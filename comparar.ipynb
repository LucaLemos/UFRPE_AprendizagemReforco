{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir uma rede neural simples para Q-learning\n",
    "class SimpleQNetwork(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size=128):\n",
    "        super(SimpleQNetwork, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = torch.nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Função para carregar um modelo treinado\n",
    "def load_model(env_name, model_type, hidden_size):\n",
    "    env = gym.make(env_name)\n",
    "    input_size = env.observation_space.n\n",
    "    output_size = env.action_space.n\n",
    "    model = SimpleQNetwork(input_size, output_size, hidden_size)\n",
    "    model.load_state_dict(torch.load(f\"trained_models/{env_name}{model_type}.pth\"))\n",
    "    model.eval()  # Coloca o modelo em modo de avaliação\n",
    "    env.close()  # Fechar o ambiente após usar\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para avaliar um modelo\n",
    "def evaluate_model(env, model, num_episodes=50, max_steps_per_episode=1000):\n",
    "    total_rewards = []\n",
    "    total_steps = []\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        print(f\"Episódio {episode + 1}/{num_episodes}\")\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        episode_steps = 0\n",
    "        \n",
    "        while not done and episode_steps < max_steps_per_episode:\n",
    "            state_tensor = torch.tensor([state], dtype=torch.long)\n",
    "            state_tensor = to_one_hot(state_tensor, model.fc1.in_features)[0].float().unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                q_values = model(state_tensor)\n",
    "                action = torch.argmax(q_values).item()\n",
    "            state, reward, done, truncated, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "            episode_steps += 1\n",
    "        \n",
    "        total_rewards.append(episode_reward)\n",
    "        total_steps.append(episode_steps)\n",
    "    \n",
    "    avg_reward = np.mean(total_rewards)\n",
    "    std_reward = np.std(total_rewards)\n",
    "    avg_steps = np.mean(total_steps)\n",
    "    std_steps = np.std(total_steps)\n",
    "    \n",
    "    return avg_reward, std_reward, avg_steps, std_steps, total_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para comparar os métodos\n",
    "def compare_methods(env_name, hidden_size, num_episodes=50):\n",
    "    env = gym.make(env_name)\n",
    "    \n",
    "    # Carregar modelos CQL-DQN e FQI-DQN\n",
    "    cql_model = load_model(env_name, \"CQL-DQN\", hidden_size)\n",
    "    fqi_model = load_model(env_name, \"FQI-DQN\", hidden_size)\n",
    "    \n",
    "    # Avaliar modelos\n",
    "    cql_avg_reward, cql_std_reward, cql_avg_steps, cql_std_steps, cql_rewards = evaluate_model(env, cql_model, num_episodes)\n",
    "    fqi_avg_reward, fqi_std_reward, fqi_avg_steps, fqi_std_steps, fqi_rewards = evaluate_model(env, fqi_model, num_episodes)\n",
    "    \n",
    "    # Exibir resultados\n",
    "    print(f\"Ambiente: {env_name}\")\n",
    "    print(f\"Método: CQL-DQN\")\n",
    "    print(f\"  Recompensa média: {cql_avg_reward:.2f} ± {cql_std_reward:.2f}\")\n",
    "    print(f\"  Passos médios por episódio: {cql_avg_steps:.2f} ± {cql_std_steps:.2f}\")\n",
    "    print(f\"Método: FQI-DQN\")\n",
    "    print(f\"  Recompensa média: {fqi_avg_reward:.2f} ± {fqi_std_reward:.2f}\")\n",
    "    print(f\"  Passos médios por episódio: {fqi_avg_steps:.2f} ± {fqi_std_steps:.2f}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Plotar gráfico de comparação de recompensas\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(cql_rewards, label=\"CQL-DQN\", alpha=0.7)\n",
    "    plt.plot(fqi_rewards, label=\"FQI-DQN\", alpha=0.7)\n",
    "    plt.xlabel(\"Episódio\")\n",
    "    plt.ylabel(\"Recompensa\")\n",
    "    plt.title(f\"Comparação de Recompensas - {env_name}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Função para codificar estados em one-hot\n",
    "def to_one_hot(state_tensor, num_states):\n",
    "    return torch.zeros(state_tensor.size(0), num_states).scatter_(1, state_tensor.unsqueeze(1), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar métodos para cada ambiente\n",
    "if __name__ == \"__main__\":\n",
    "    envs = [\n",
    "        (\"FrozenLake-v1\", 128),\n",
    "        (\"Taxi-v3\", 512),\n",
    "        (\"CliffWalking-v0\", 256)\n",
    "    ]\n",
    "    \n",
    "    for env_name, hidden_size in envs:\n",
    "        compare_methods(env_name, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
